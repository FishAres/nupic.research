{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cont_speech_experiment import ContinuousSpeechExperiment, ClasswiseDataset\n",
    "from nupic.research.support import parse_config\n",
    "\n",
    "from nupic.research.frameworks.continuous_learning.utils import (\n",
    "    clear_labels,\n",
    "    freeze_output_layer,\n",
    "    split_inds,\n",
    ")\n",
    "    \n",
    "from exp_lesparse import LeSparseNet\n",
    "\n",
    "import os\n",
    "\n",
    "from nupic.research.frameworks.pytorch.model_utils import evaluate_model\n",
    "from nupic.research.frameworks.continuous_learning.dendrite_layers import (\n",
    "    DendriteLayer, DendriteInput, DendriteOutput\n",
    ")\n",
    "from nupic.torch.modules import (\n",
    "    Flatten,\n",
    "    KWinners,\n",
    "    KWinners2d,\n",
    "    SparseWeights,\n",
    "    SparseWeights2d,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating optimizer with learning rate= 0.01\n"
     ]
    }
   ],
   "source": [
    "config_file = \"../experiments.cfg\"\n",
    "with open(config_file) as cf:\n",
    "    config_init = parse_config(cf)\n",
    "    \n",
    "exp = \"sparseCNN2\"\n",
    "\n",
    "config = config_init[exp]\n",
    "config[\"name\"] = exp\n",
    "config[\"use_dendrites\"] = False\n",
    "config[\"use_batch_norm\"] = True\n",
    "config[\"cnn_out_channels\"] = (128, 128)\n",
    "config[\"cnn_percent_on\"] = (1., 1.) # 0.2 0.2\n",
    "config[\"cnn_weight_sparsity\"] = (1., 1.) # 0.55 0.55\n",
    "config[\"dendrites_per_cell\"] = 2\n",
    "config[\"batch_size\"] = 64\n",
    "experiment = ContinuousSpeechExperiment(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules, indices = [], []\n",
    "module_sizes = [128, 128, 1000, 11]\n",
    "cnt = 0\n",
    "for module in experiment.model:\n",
    "    if hasattr(module, \"weight_sparsity\"):\n",
    "        inds = split_inds(module, 2, module_sizes[cnt])\n",
    "        final_inds = [np.delete(np.arange(module_sizes[cnt]), kidx) for kidx in inds]\n",
    "        modules.append(module)\n",
    "        indices.append(final_inds)\n",
    "        \n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds = np.random.permutation(np.arange(1,5)).reshape(2,2)\n",
    "for j in range(len(train_inds)):\n",
    "    temp_inds = [k[j] for k in indices]\n",
    "    experiment.train(1, train_inds[j], freeze_modules=modules[:-1], module_inds=temp_inds[:-1],\n",
    "                    freeze_output=True, output_indices=clear_labels(train_inds[j],5),\n",
    "                     layer_type=\"kwinner\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25.0, 13.28125, 84.765625, 68.22916666666666]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[experiment.test_class(k)[\"mean_accuracy\"] for k in train_inds.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inds[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbff71c7b50>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(experiment.running_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(0., device='cuda:0')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 0\n",
    "a,b = list(modules[ind].named_parameters())\n",
    "[a[1].grad[k,...].mean() for k in temp_inds[ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 795 is out of bounds for dimension 0 with size 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-976a486c03d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_inds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-105-976a486c03d4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_inds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 795 is out of bounds for dimension 0 with size 128"
     ]
    }
   ],
   "source": [
    "w = list(experiment.model.named_parameters())\n",
    "[w[2][1].grad[k,...].mean() for k in temp_inds[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fbff40bbad0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_grads(module, inds):\n",
    "    with torch.no_grad():\n",
    "        weight_grads, bias_grads = list(module.parameters())\n",
    "        if len(weight_grads.shape) > 2:\n",
    "            [weight_grads.data[index,:,:,:].fill_(0.0) for index in inds]\n",
    "        else:\n",
    "            [weight_grads.data[index,:].fill_(0.0) for index in inds]\n",
    "        [bias_grads.data[index].fill_(0.0) for index in inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    freeze_modules=None,\n",
    "    freeze_splits=5,\n",
    "    freeze_output=False,\n",
    "    layer_type=\"dense\",\n",
    "    linear_number=2,\n",
    "    output_indices=None,\n",
    "    criterion=F.nll_loss,\n",
    "    batches_in_epoch=sys.maxsize,\n",
    "    pre_batch_callback=None,\n",
    "    post_batch_callback=None,\n",
    "    progress_bar=None,\n",
    "    combine_data=False,\n",
    "):\n",
    "\n",
    "    model.train()\n",
    "    # Use asynchronous GPU copies when the memory is pinned\n",
    "    # See https://pytorch.org/docs/master/notes/cuda.html\n",
    "    async_gpu = loader.pin_memory\n",
    "    if progress_bar is not None:\n",
    "        loader = tqdm(loader, **progress_bar)\n",
    "        # update progress bar total based on batches_in_epoch\n",
    "        if batches_in_epoch < len(loader):\n",
    "            loader.total = batches_in_epoch\n",
    "\n",
    "    # Check if training with Apex Mixed Precision\n",
    "    use_amp = hasattr(optimizer, \"_amp_stash\")\n",
    "    try:\n",
    "        from apex import amp\n",
    "    except ImportError:\n",
    "        if use_amp:\n",
    "            raise ImportError(\n",
    "                \"Mixed precision requires NVIDA APEX.\"\n",
    "                \"Please install apex from https://www.github.com/nvidia/apex\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        if batch_idx >= batches_in_epoch:\n",
    "            break\n",
    "\n",
    "        num_images = len(target)\n",
    "        data = data.to(device, non_blocking=async_gpu)\n",
    "        target = target.to(device, non_blocking=async_gpu)\n",
    "        t1 = time.time()\n",
    "\n",
    "        if pre_batch_callback is not None:\n",
    "            pre_batch_callback(model=model, batch_idx=batch_idx)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if combine_data:\n",
    "            output = model(data, target)\n",
    "        else:\n",
    "            output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        del data, target, output\n",
    "\n",
    "        t2 = time.time()\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        if freeze_modules is not None:\n",
    "            for mod_ in freeze_modules:\n",
    "                module, inds = get_inds(mod_, freeze_splits)\n",
    "                freeze_grads(module, inds)\n",
    "\n",
    "        if freeze_output:\n",
    "            freeze_output_layer(model, output_indices, layer_type=layer_type,\n",
    "                                linear_number=linear_number)\n",
    "\n",
    "        t3 = time.time()\n",
    "        optimizer.step() # step\n",
    "        t4 = time.time()\n",
    "\n",
    "        if post_batch_callback is not None:\n",
    "            time_string = (\"Data: {:.3f}s, forward: {:.3f}s, backward: {:.3f}s,\"\n",
    "                           + \"weight update: {:.3f}s\").format(t1 - t0, t2 - t1, t3 - t2,\n",
    "                                                              t4 - t3)\n",
    "            post_batch_callback(model=model, loss=loss.detach(), batch_idx=batch_idx,\n",
    "                                num_images=num_images, time_string=time_string)\n",
    "        del loss\n",
    "        t0 = time.time()\n",
    "\n",
    "    if progress_bar is not None:\n",
    "        loader.n = loader.total\n",
    "        loader.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeSparseNet(\n",
       "  (cnn1_cnn): SparseWeights2d(\n",
       "    sparsity=0.85\n",
       "    (module): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       "  (cnn1_kwinner): KWinners2d(channels=128, local=False, n=0, percent_on=0.12, boost_strength=1.5, boost_strength_factor=0.9, k_inference_factor=1.0, duty_cycle_period=1000)\n",
       "  (cnn1_maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (cnn2_cnn): SparseWeights2d(\n",
       "    sparsity=0.95\n",
       "    (module): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       "  (cnn2_kwinner): KWinners2d(channels=128, local=False, n=0, percent_on=0.07, boost_strength=1.5, boost_strength_factor=0.9, k_inference_factor=1.0, duty_cycle_period=1000)\n",
       "  (cnn2_maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten()\n",
       "  (linear1): SparseWeights(\n",
       "    sparsity=0.8\n",
       "    (module): Linear(in_features=3200, out_features=1000, bias=True)\n",
       "  )\n",
       "  (linear1_kwinners): KWinners(n=1000, percent_on=0.1, boost_strength=1.5, boost_strength_factor=0.9, k_inference_factor=1.0, duty_cycle_period=1000)\n",
       "  (linear2): SparseWeights(\n",
       "    sparsity=0.8\n",
       "    (module): Linear(in_features=1000, out_features=11, bias=True)\n",
       "  )\n",
       "  (linear2_kwinners): KWinners(n=11, percent_on=0.2, boost_strength=1.5, boost_strength_factor=0.9, k_inference_factor=1.0, duty_cycle_period=1000)\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 3, 4, 9, 5, 6, 8, 2, 1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
